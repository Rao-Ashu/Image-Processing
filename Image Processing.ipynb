{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage # sibling of sklearn but for Image PRocessing\n",
    "import numpy as np # we all know\n",
    "import pandas as pd # evolved numpy\n",
    "import matplotlib.pyplot as plt # This one is a true creator\n",
    "import warnings # No one liked warnings\n",
    "from keras.datasets import cifar10 # image data\n",
    "import random # to perform random tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') # ignore all warning because I don't care what they say, I gotta learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Plotting Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chelsea = skimage.data.chelsea() # data is given here already\n",
    "print(chelsea.shape)\n",
    "plt.imshow(chelsea)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip and Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.fliplr(chelsea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.transform.rotate(chelsea,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(chelsea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_chelsea = chelsea.copy()\n",
    "mask = (blue_chelsea[:,:,0]>103) & (blue_chelsea[:,:,0]<153)  # get random pixels based on a condition\n",
    "blue_chelsea[mask] = [0,0,255] # turn the mask as blue\n",
    "plt.imshow(blue_chelsea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color scheme Conversion\n",
    "\n",
    "### RGB to Grayscale\n",
    "3 channels merged into one. 0-255 range becomes 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.color.rgb2gray(chelsea),cmap='gray') # RGB to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert colors\n",
    "High intensity pixels are interchanges with low intensity pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.util.invert(chelsea)) # inverted colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGR_chelsea = chelsea[:,:,::-1]\n",
    "plt.imshow(BGR_chelsea) # RGB to BGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img,y,x):\n",
    "    h,w,c = img.shape\n",
    "    start_w = w//2 - (x//2)\n",
    "    start_h = h//2 - (y//2)\n",
    "    return img[start_h:start_h+y,start_w:start_w+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_center(chelsea,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "A lying or standing cat is still a cat due to its features not the location of features. Convolution layers sometimes give importance to the location so pooling tries to minimize that effect.\n",
    "[Pooling Layers](https://iq.opengenus.org/pooling-layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = skimage.color.rgb2gray(chelsea)\n",
    "resized = skimage.transform.resize(gray,(300,448)) # original is 300,451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal = (4,4) # or block\n",
    "blocked = skimage.util.view_as_blocks(resized,kernal)\n",
    "# w,h should be completely divided by kernal size\n",
    "blocked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image while preserving the Width and Height OR simply merge color and patches channels\n",
    "reshaped = blocked.reshape(blocked.shape[0],blocked.shape[1],-1)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAx pooling\n",
    "max_pooled = np.max(reshaped,axis=2)\n",
    "avg_pooled = np.mean(reshaped,axis=2)\n",
    "min_pooled = np.min(reshaped,axis=2)\n",
    "med_pooled = np.median(reshaped,axis=2)\n",
    "\n",
    "f,ax = plt.subplots(2,2,figsize=(15,8))\n",
    "ax = ax.ravel()\n",
    "\n",
    "ax[0].imshow(max_pooled,cmap='gray')\n",
    "ax[0].set_title('Max Pooled')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(min_pooled,cmap='gray')\n",
    "ax[1].set_title('Min Pooled')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(avg_pooled,cmap='gray')\n",
    "ax[2].set_title('Average Pooled')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(med_pooled,cmap='gray')\n",
    "ax[3].set_title('Median Pooled')\n",
    "ax[3].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZCA Whitening and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,_),(images,_) = cifar10.load_data() \n",
    "# (X_train,y_tain),(x_test,y_test) but we need less in quantity so we just imported x_test\n",
    "\n",
    "images = images[:1000] # just use the first 1000 images for demo\n",
    "\n",
    "print(f'Shape of images array is: {images.shape}')\n",
    "\n",
    "f,ax = plt.subplots(1,3,figsize=(5,5))\n",
    "ax = ax.ravel()\n",
    "for i in range(3):\n",
    "    ax[i].imshow(images[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(-1,(32*32*3)) # -1 means it choses the best suitable i.e 1000 in our case\n",
    "print(f' new shape of images is {images.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA Whitening\n",
    "ZCA decorrelates the Image Features or transforms the image in such a way that makes the covariance matrix of the image as identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # find the covariance matrix. i.e how much two variables change together\n",
    "cov_mat = np.cov(images)\n",
    "\n",
    "# singular value decomposition SVD (dimensionality reduction technique to find  hidden latent features)\n",
    "# a plastic bag, douchebag and a weapon can have a latent feature that they are all from USA ;)\n",
    "U,S,V = np.linalg.svd(cov_mat)\n",
    "\n",
    "# dot product to get the principal components\n",
    "epsilon = 0.000001 # avoid division by zero\n",
    "w = np.diag(1.0/np.sqrt(S+epsilon)) # diagonal matrix\n",
    "x = np.dot(w,U.T) # U transpose     \n",
    "components = np.dot(U,x)\n",
    "\n",
    "# calculate zca by using dot products of the principal components by images \n",
    "zca_images = np.dot(components,images)\n",
    "zca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,3,figsize=(5,5))\n",
    "ax = ax.ravel()\n",
    "for i in range(3):\n",
    "    # clip the images in some range for matplotlib else it'll throw error\n",
    "    img = zca_images[i].reshape((32,32,3))\n",
    "    min_,max_ = img.min(), img.max()\n",
    "    ax[i].imshow((img-min_)/(max_-min_))  # clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Normalization makes the pixel centered of image around mean 0 by subtracting the pixels of an image from the mean of whole **batch** of images and dividing by the standard deviation of the **batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images - images.mean(axis=0) # subtract the mean of whole 10000 images from each image\n",
    "images = images/images.std(axis=0) # divide by the standard deviation\n",
    "\n",
    "f,ax = plt.subplots(1,3,figsize=(5,5))\n",
    "ax = ax.ravel()\n",
    "for i in range(3):\n",
    "    # clip the images in some range for matplotlib else it'll throw error\n",
    "    img = images[i].reshape((32,32,3))\n",
    "    min_,max_ = img.min(), img.max()\n",
    "    ax[i].imshow((img-min_)/(max_-min_))  # clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-Noising\n",
    "To save time here, let us just resize the image then we will add Gaussian Noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = skimage.transform.resize(chelsea,(chelsea.shape[0]//2,chelsea.shape[1]//2)) \n",
    "# resize to half preserving the aspect ratio\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Gaussian Noise\n",
    "sigma = 0.17 # defines the type/shape of distribution high sigma = high noise\n",
    "noised = skimage.util.random_noise(resized,mode='gaussian', var=sigma**2)\n",
    "plt.imshow(noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if our image has Gaussian noise, this can detect and tell us the sigma. Our result is close to our sigma\n",
    "\n",
    "skimage.restoration.estimate_sigma(noised,multichannel=True,average_sigmas=True)\n",
    "# we want to calculate the noise for each of the RGB channel (multichannel=True) and want avg. for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TV Chambolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it makes the 'normalization' value close to the normal image by using 100 iteration by default\n",
    "\n",
    "tv_cham = skimage.restoration.denoise_tv_chambolle(noised,multichannel=True,weight=0.12)\n",
    "plt.imshow(tv_cham)\n",
    "# output depends on the weight. High value of weight makes the image blurry and far from original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this preserves the edges and works on closeness of pixels (spatial closeness) and \n",
    "# how two pixels are similar in their color channels (radiometric similarity)\n",
    "\n",
    "bilat = skimage.restoration.denoise_bilateral(noised,multichannel=True,sigma_color=0.09,sigma_spatial=1.3)\n",
    "plt.imshow(bilat)\n",
    "# both the sigma as parameters are standard deviations for spatial closeness and radiometric similarity\n",
    "# try to use high sigma_spatial. It'll take lot of time and the black portion at the bottom will increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works on the wavelength representation of image and follows the luminosity (Y) and chroma components\n",
    "# (Cb,Cr) so it is YCbCr instead of RGB format\n",
    "\n",
    "wave = skimage.restoration.denoise_wavelet(noised,multichannel=True,wavelet='db2',method='VisuShrink')\n",
    "plt.imshow(wave)\n",
    "\n",
    "# try to read the documentation about the parameters. These vary from image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Local Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes a mean of all pixels, weighted by how similar these pixels are to the target pixel. \n",
    "# This results in greater post-filtering clarity than local means\n",
    "nl_mean = skimage.restoration.denoise_nl_means(noised,multichannel=True,patch_size=6,patch_distance=13)\n",
    "plt.imshow(nl_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git init\n",
    "! git add -A\n",
    "! git commit -m \"ZCA \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
